{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Logictrix_AI_ML_task_2.ipynb",
      "provenance": [],
      "mount_file_id": "1d5_Y0639Zh678bsytPFtXRxojlv1wIoS",
      "authorship_tag": "ABX9TyNTqibWwRqAs750gAiqvC6o",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Bhavesh0510/Logictrix_task/blob/main/Logictrix_AI_ML_task_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iaLmhkCFFr-O",
        "outputId": "efba4202-f081-413f-ec06-0906945516df"
      },
      "source": [
        "import glob\n",
        "total = 0\n",
        "for i in glob.glob(\"/content/drive/MyDrive/Logictrix_task_2/train/*\"):\n",
        "    total = total + 1\n",
        "\n",
        "print(\"Total images are:\",total)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total images are: 1671\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KrCuL0P_GQRA"
      },
      "source": [
        "from PIL import Image,ImageEnhance\n",
        "import random\n",
        "num = 0\n",
        "for j in glob.glob(\"/content/drive/MyDrive/Logictrix_task_2/train/*\"):\n",
        "    img = Image.open(j)\n",
        "    enhancer = ImageEnhance.Contrast(img)\n",
        "    img_o = enhancer.enhance(random.uniform(0.1,0.5))\n",
        "    img_o.save(f\"/content/drive/MyDrive/Logictrix_task_2/train_dataset/low/{num}.jpg\")\n",
        "    num = num + 1\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JwXxxuF0J_77"
      },
      "source": [
        "from PIL import Image,ImageEnhance\n",
        "import random\n",
        "num = 0\n",
        "for j in glob.glob(\"/content/drive/MyDrive/Logictrix_task_2/train/*\"):\n",
        "    img = Image.open(j)\n",
        "    enhancer = ImageEnhance.Contrast(img)\n",
        "    img_o = enhancer.enhance(random.uniform(1.4,2.9))\n",
        "    img_o.save(f\"/content/drive/MyDrive/Logictrix_task_2/train_dataset/high/{num}.jpg\")\n",
        "    num = num + 1"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tF2RuNf5L8k2",
        "outputId": "c3306566-fde7-4d01-eafe-10135da86eae"
      },
      "source": [
        "import os\n",
        "Main_DIR = \"/content/drive/MyDrive/Logictrix_task_2/train_dataset/\"\n",
        "os.listdir(Main_DIR)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['high', 'low']"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "muK-J6SxNDan"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-mmkWO9wOZkl"
      },
      "source": [
        "from tensorflow.keras.layers import Input, Lambda, Dense, Flatten\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "from tensorflow.keras.applications.inception_v3 import preprocess_input\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator,load_img\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D,ZeroPadding2D,BatchNormalization,Activation\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dense\n",
        "from keras.preprocessing import image\n",
        "from tensorflow.keras.preprocessing import image_dataset_from_directory\n"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MbjB0z3HQb1Q",
        "outputId": "9b709ef2-8faf-4431-e857-495086d177e1"
      },
      "source": [
        "Batch_size = 32\n",
        "Image_size = (320,320)\n",
        "training_ds = image_dataset_from_directory(\n",
        "    Main_DIR,\n",
        "    batch_size = Batch_size,\n",
        "    image_size = Image_size,\n",
        "    shuffle = True,\n",
        "    seed = 42,\n",
        "    validation_split = 0.33,\n",
        "    subset = \"training\",\n",
        ")\n",
        "validation_ds = image_dataset_from_directory(\n",
        "    Main_DIR,\n",
        "    batch_size = Batch_size,\n",
        "    image_size = Image_size,\n",
        "    shuffle = True,\n",
        "    seed = 42,\n",
        "    validation_split = 0.33,\n",
        "    subset = \"validation\",\n",
        ")"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 3342 files belonging to 2 classes.\n",
            "Using 2240 files for training.\n",
            "Found 3342 files belonging to 2 classes.\n",
            "Using 1102 files for validation.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MOuERjxORiPX"
      },
      "source": [
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "training_ds = training_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
        "validation_ds = validation_ds.cache().prefetch(buffer_size=AUTOTUNE)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZjRXHmuqR0ZE"
      },
      "source": [
        "normalize_layer = tf.keras.layers.experimental.preprocessing.Rescaling(1./255)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YXNF9tgCSCOJ"
      },
      "source": [
        "training_ds = training_ds.map(lambda x,y: (normalize_layer(x),y))\n",
        "validation_ds = validation_ds.map(lambda x,y: (normalize_layer(x), y))\n"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fo1BX-01Sp74"
      },
      "source": [
        "\n",
        "def create_model(input_shape = (320,320,3)):\n",
        "  x_input = Input(input_shape)\n",
        "  x = ZeroPadding2D((3,3))(x_input)\n",
        "\n",
        "  x = Conv2D(filters=16,kernel_size=(3,3),padding=\"same\")(x)\n",
        "  x = BatchNormalization(axis=3)(x)\n",
        "  x = Activation(\"relu\")(x)\n",
        "  x = MaxPooling2D(pool_size=(2,2))(x)\n",
        "\n",
        "  x = Conv2D(filters=32,kernel_size=(3,3),padding=\"same\")(x)\n",
        "  x = BatchNormalization(axis=3)(x)\n",
        "  x = Activation(\"relu\")(x)\n",
        "  x = MaxPooling2D(pool_size=(2,2))(x)\n",
        "\n",
        "  x = Conv2D(filters=64,kernel_size=(3,3),padding=\"same\")(x)\n",
        "  x = BatchNormalization(axis=3)(x)\n",
        "  x = Activation(\"relu\")(x)\n",
        "  x = MaxPooling2D(pool_size=(2,2))(x)\n",
        "\n",
        "  x = Conv2D(filters=128,kernel_size=(3,3),padding=\"same\")(x)\n",
        "  x = BatchNormalization(axis=3)(x)\n",
        "  x = Activation(\"relu\")(x)\n",
        "  x = MaxPooling2D(pool_size=(2,2))(x)\n",
        "\n",
        "  x = Flatten()(x)\n",
        "  x = Dense(units=128, activation=\"relu\")(x)\n",
        "  x = Dense(units = 1)(x)\n",
        "\n",
        "  mod = Model(inputs=x_input, outputs=x)\n",
        "  return mod"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VLivCei_S8l6"
      },
      "source": [
        "model = create_model()"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JNro9S9gTqii"
      },
      "source": [
        "model.compile(\n",
        "    optimizer = tf.keras.optimizers.Adam(),\n",
        "    loss = tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "    metrics = [\"accuracy\"]\n",
        ")"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TtEeLwVpT1Cj",
        "outputId": "dd7996ac-61ea-4e61-ee70-2835e38d43e6"
      },
      "source": [
        "epochs = 5\n",
        "history = model.fit(\n",
        "    training_ds,\n",
        "    epochs=epochs\n",
        ")"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "70/70 [==============================] - 342s 5s/step - loss: 0.2347 - accuracy: 0.9906\n",
            "Epoch 2/5\n",
            "70/70 [==============================] - 344s 5s/step - loss: 0.1202 - accuracy: 0.9933\n",
            "Epoch 3/5\n",
            "70/70 [==============================] - 350s 5s/step - loss: 0.0286 - accuracy: 0.9960\n",
            "Epoch 4/5\n",
            "70/70 [==============================] - 343s 5s/step - loss: 0.0472 - accuracy: 0.9973\n",
            "Epoch 5/5\n",
            "70/70 [==============================] - 345s 5s/step - loss: 0.1222 - accuracy: 0.9951\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}